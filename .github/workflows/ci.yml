name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  contents: read
  actions: read

jobs:
  secret-scan:
    name: Secret scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          fetch-depth: 0

      - name: Run gitleaks
        uses: gitleaks/gitleaks-action@ff98106e4c7b2bc287b24eaf42907196329070c7 # v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }}

  workflow-lint:
    name: Workflow lint (actionlint)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Run actionlint
        uses: rhysd/actionlint@0933c147c9d6587653d45fdcb4c497c57a65f9af # v1.7.10

  spec-sanity:
    name: Spec sanity checks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.11'

      - name: Validate JSON files parse
        run: |
          python -m json.tool test_vectors/schema.json >/dev/null
          python - <<'PY'
          import json
          from pathlib import Path
          
          schema = Path("test_vectors/schema.json")
          json.loads(schema.read_text(encoding="utf-8"))
          
          vectors = sorted(Path("test_vectors").glob("v*/vectors.json"))
          if not vectors:
            raise SystemExit("No vectors found under test_vectors/v*/vectors.json")
          
          for p in vectors:
            json.loads(p.read_text(encoding="utf-8"))
            print("OK:", p)
          PY

      - name: Validate vectors JSON has required keys
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          required = ("version", "generated", "vectors")
          
          vectors = sorted(Path("test_vectors").glob("v*/vectors.json"))
          if not vectors:
            raise SystemExit("No vectors found under test_vectors/v*/vectors.json")
          
          for p in vectors:
            data = json.loads(p.read_text(encoding="utf-8"))
            for k in required:
              if k not in data:
                raise SystemExit(f"Missing key {k!r} in {p}")
            if not isinstance(data["vectors"], list):
              raise SystemExit(f"'vectors' must be a list in {p}")
            print("OK keys:", p)
          PY

      - name: Python syntax check (research code)
        run: |
          python -m compileall -q research/security-validation

  docs-links:
    name: Docs link sanity (relative links)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.11'

      - name: Validate relative links in Markdown/HTML
        run: |
          python - <<'PY'
          import re
          from pathlib import Path
          from urllib.parse import urlparse
          
          ROOT = Path(".").resolve()
          
          # Markdown: [text](target) and ![alt](target)
          MD_LINK_RE = re.compile(r"!?\\[[^\\]]*\\]\\(([^)]+)\\)")
          # HTML: href="..." and src="..."
          HTML_ATTR_RE = re.compile(r'\\b(?:href|src)=["\\\']([^"\\\']+)["\\\']')
          
          def is_external(target: str) -> bool:
              t = target.strip()
              if not t:
                  return True
              if t.startswith("#"):
                  return True
              if t.startswith("mailto:"):
                  return True
              if t.startswith("tel:"):
                  return True
              if t.startswith("data:"):
                  return True
              p = urlparse(t)
              return bool(p.scheme) and p.scheme not in ("file",)
          
          def normalize_target(target: str) -> str:
              t = target.strip()
              # strip surrounding angle brackets sometimes used in MD autolinks: (<path>)
              if t.startswith("<") and t.endswith(">"):
                  t = t[1:-1].strip()
              # drop query/fragment
              t = t.split("?", 1)[0]
              t = t.split("#", 1)[0]
              return t.strip()
          
          def check_file_link(src_file: Path, target: str) -> tuple[bool, str]:
              if is_external(target):
                  return True, ""
              t = normalize_target(target)
              if not t or t.startswith("#"):
                  return True, ""
              # treat absolute-from-root paths as repo-root relative
              if t.startswith("/"):
                  candidate = (ROOT / t.lstrip("/")).resolve()
              else:
                  candidate = (src_file.parent / t).resolve()
              try:
                  candidate.relative_to(ROOT)
              except Exception:
                  return False, f"escapes repo root: {target}"
              if candidate.exists():
                  return True, ""
              return False, f"missing: {target} -> {candidate.relative_to(ROOT)}"
          
          failures: list[str] = []
          files = list(ROOT.rglob("*.md")) + list(ROOT.rglob("*.html"))
          
          for f in files:
              # skip vendor/large generated zones if any appear later
              rel = f.relative_to(ROOT)
              if any(part in {".git", "node_modules"} for part in rel.parts):
                  continue
              text = f.read_text(encoding="utf-8", errors="replace")
              targets = []
              if f.suffix == ".md":
                  targets = [m.group(1) for m in MD_LINK_RE.finditer(text)]
              elif f.suffix == ".html":
                  targets = [m.group(1) for m in HTML_ATTR_RE.finditer(text)]
              
              for t in targets:
                  ok, msg = check_file_link(f, t)
                  if not ok:
                      failures.append(f"{rel}: {msg}")
          
          if failures:
              print("Broken relative links found:")
              for line in failures:
                  print(" -", line)
              raise SystemExit(1)
          
          print(f"OK: validated relative links in {len(files)} files")
          PY

  whitepaper-build:
    name: Whitepaper build (LaTeX)
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Install LaTeX toolchain
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends \
            latexmk \
            texlive-latex-extra \
            texlive-fonts-recommended \
            texlive-science

      - name: Build whitepaper PDF
        run: |
          set -euo pipefail
          latexmk -pdf -interaction=nonstopmode -halt-on-error -file-line-error -cd whitepaper/WHITEPAPER.tex

